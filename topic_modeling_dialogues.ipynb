{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset with extracted dialogues"
      ],
      "metadata": {
        "id": "Q3S39LsIzaOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9f7qOHBWcfVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/masters/try/last dataset/edited_dataset.csv')"
      ],
      "metadata": {
        "id": "mlhiE1S7dNPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries "
      ],
      "metadata": {
        "id": "01hCeCzJzhDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi7gTrLdbsXY",
        "outputId": "c9e7a5f6-aafb-4a41-d845-bc80fec6fe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natasha in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: slovnet>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.6.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.15.1)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.10/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec>=0.9.0->natasha) (1.24.3)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgAVHSDFbxs_",
        "outputId": "ccc98be4-c23b-4c3a-a0e7-1fab02303ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import download as nltk_download \n",
        "nltk_download ('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7awMQpLvzCxq",
        "outputId": "782be386-ee44-4087-bcc5-76d332816b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, NewsNERTagger, Doc)\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)"
      ],
      "metadata": {
        "id": "mvaf2b-6zQhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "parser = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "rgLGPLsVzRnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGvmft9-ztPH",
        "outputId": "936a1b20-7895-4156-ea02-b339b4e6c204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "fTr1l2i6_wtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial black list"
      ],
      "metadata": {
        "id": "0QUHoyLezzDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dhhse/dh2020/master/data/stop_ru.txt\n",
        "with open ('stop_ru.txt', 'r') as stop_file:\n",
        "    rus_stops = [word.strip() for word in stop_file.readlines()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwdrXXXzIFI",
        "outputId": "6588c6ff-e5b8-4c7c-c1a6-a6069b341978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-11 22:51:53--  https://raw.githubusercontent.com/dhhse/dh2020/master/data/stop_ru.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5823 (5.7K) [text/plain]\n",
            "Saving to: ‘stop_ru.txt’\n",
            "\n",
            "stop_ru.txt         100%[===================>]   5.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-11 22:51:53 (76.9 MB/s) - ‘stop_ru.txt’ saved [5823/5823]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = '!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~—»«...–'\n"
      ],
      "metadata": {
        "id": "RYJeFPnTz1IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling"
      ],
      "metadata": {
        "id": "6qZkP1cdz7tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "6bQPPNG-Rcho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input_text):\n",
        "    tokenized_text = word_tokenize(input_text.lower())\n",
        "    output_text = [word for word in tokenized_text if word not in filters]\n",
        "    clean_text = [word for word in output_text if word.isalpha()]\n",
        "    lemmatized_text = [parser.parse(word)[0].normal_form for word in clean_text]\n",
        "    return lemmatized_text"
      ],
      "metadata": {
        "id": "46uC54Tr1u6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = []\n",
        "titles = []\n",
        "topics = []"
      ],
      "metadata": {
        "id": "guOei5EnfXMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(dataset['dialogues'].tolist())):\n",
        "  text = dataset['dialogues'].tolist()[index]\n",
        "  text_list = []\n",
        "  text_list.append(text)\n",
        "  doc_natasha = Doc(text)\n",
        "  doc_natasha.segment(segmenter)\n",
        "  doc_natasha.tag_morph(morph_tagger)\n",
        "  doc_natasha.parse_syntax(syntax_parser)\n",
        "  doc_natasha.tag_ner(ner_tagger)\n",
        "\n",
        "  names = []\n",
        "  for span in doc_natasha.spans:\n",
        "    if span.type == 'PER':\n",
        "      if span.text not in names:\n",
        "        names.append(span.text)\n",
        "      span.normalize(morph_vocab)\n",
        "      if span.normal not in names:\n",
        "        names.append(span.normal)\n",
        "  filters = rus_stops + list(punctuation)\n",
        "  for name in names:\n",
        "    word = name.lower()\n",
        "    filters = filters + word.split(' ')\n",
        "  print(filters)\n",
        "  preprocessed_texts = [preprocess(text_t) for text_t in text_list]\n",
        "  gensim_dictionary_for_TM = gensim.corpora.Dictionary(preprocessed_texts)\n",
        "  gensim_dictionary_for_TM.compactify()\n",
        "  corpus = [gensim_dictionary_for_TM.doc2bow(text_p) for text_p in preprocessed_texts]\n",
        "  lda = gensim.models.LdaMulticore(corpus,num_topics = 10, id2word=gensim_dictionary_for_TM, passes=10)\n",
        "  topics_book = []\n",
        "  for topic in lda.print_topics():\n",
        "    topic_extracted = re.findall(r'(?<=\")\\w.*?(?=\")', topic[1])\n",
        "    for i in topic_extracted:\n",
        "      if i not in topics_book:\n",
        "        topics_book.append(i)\n",
        "  \n",
        "  author = dataset['author'].tolist()[index]\n",
        "  authors.append(author)\n",
        "  # extract book title \n",
        "  title = dataset['book'].tolist()[index]\n",
        "  titles.append(title)\n",
        "  # topics \n",
        "  topics.append(topics_book)\n",
        "\n",
        "df_columns = ['author', 'book', 'topics']\n",
        "dataframe = pd.DataFrame(columns = df_columns)\n",
        "dataframe['author'] = authors\n",
        "dataframe['book'] = titles\n",
        "dataframe['topics'] = topics\n",
        "\n",
        "# creating a dataset \n",
        "dataframe.to_csv('topics_dialogues.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "uCSD-boAdjpd",
        "outputId": "fddcf9f5-5ce4-4d55-93f2-a7324ce80e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'а', 'е', 'и', 'ж', 'м', 'о', 'на', 'не', 'ни', 'об', 'но', 'он', 'мне', 'мои', 'мож', 'она', 'они', 'оно', 'мной', 'много', 'многочисленное', 'многочисленная', 'многочисленные', 'многочисленный', 'мною', 'мой', 'мог', 'могут', 'можно', 'может', 'можхо', 'мор', 'моя', 'моё', 'мочь', 'над', 'нее', 'оба', 'нам', 'нем', 'нами', 'ними', 'мимо', 'немного', 'одной', 'одного', 'менее', 'однажды', 'однако', 'меня', 'нему', 'меньше', 'ней', 'наверху', 'него', 'ниже', 'мало', 'надо', 'один', 'одиннадцать', 'одиннадцатый', 'назад', 'наиболее', 'недавно', 'миллионов', 'недалеко', 'между', 'низко', 'меля', 'нельзя', 'нибудь', 'непрерывно', 'наконец', 'никогда', 'никуда', 'нас', 'наш', 'нет', 'нею', 'неё', 'них', 'мира', 'наша', 'наше', 'наши', 'ничего', 'начала', 'нередко', 'несколько', 'обычно', 'опять', 'около', 'мы', 'ну', 'нх', 'от', 'отовсюду', 'особенно', 'нужно', 'очень', 'отсюда', 'в', 'во', 'вон', 'вниз', 'внизу', 'вокруг', 'вот', 'восемнадцать', 'восемнадцатый', 'восемь', 'восьмой', 'вверх', 'вам', 'вами', 'важное', 'важная', 'важные', 'важный', 'вдали', 'везде', 'ведь', 'вас', 'ваш', 'ваша', 'ваше', 'ваши', 'впрочем', 'весь', 'вдруг', 'вы', 'все', 'второй', 'всем', 'всеми', 'времени', 'время', 'всему', 'всего', 'всегда', 'всех', 'всею', 'всю', 'вся', 'всё', 'всюду', 'год', 'говорил', 'говорит', 'года', 'году', 'где', 'да', 'ее', 'за', 'из', 'ли', 'же', 'им', 'до', 'по', 'ими', 'под', 'иногда', 'довольно', 'именно', 'долго', 'позже', 'более', 'должно', 'пожалуйста', 'значит', 'иметь', 'больше', 'пока', 'ему', 'имя', 'пор', 'пора', 'потом', 'потому', 'после', 'почему', 'почти', 'посреди', 'ей', 'два', 'две', 'двенадцать', 'двенадцатый', 'двадцать', 'двадцатый', 'двух', 'его', 'дел', 'или', 'без', 'день', 'занят', 'занята', 'занято', 'заняты', 'действительно', 'давно', 'девятнадцать', 'девятнадцатый', 'девять', 'девятый', 'даже', 'алло', 'жизнь', 'далеко', 'близко', 'здесь', 'дальше', 'для', 'лет', 'зато', 'даром', 'первый', 'перед', 'затем', 'зачем', 'лишь', 'десять', 'десятый', 'ею', 'её', 'их', 'бы', 'еще', 'при', 'был', 'про', 'процентов', 'против', 'просто', 'бывает', 'бывь', 'если', 'люди', 'была', 'были', 'было', 'будем', 'будет', 'будете', 'будешь', 'прекрасно', 'буду', 'будь', 'будто', 'будут', 'ещё', 'пятнадцать', 'пятнадцатый', 'друго', 'другое', 'другой', 'другие', 'другая', 'других', 'есть', 'пять', 'быть', 'лучше', 'пятый', 'к', 'ò', 'чт', 'ком', 'конечно', 'кому', 'кого', 'когда', 'которой', 'которого', 'которая', 'которые', 'который', 'которых', 'кем', 'каждое', 'каждая', 'каждые', 'каждый', 'кажется', 'как', 'какой', 'какая', 'кто', 'кроме', 'куда', 'кругом', 'с', 'т', 'у', 'я', 'та', 'те', 'уж', 'со', 'то', 'том', 'снова', 'тому', 'совсем', 'того', 'тогда', 'тоже', 'собой', 'тобой', 'собою', 'тобою', 'сначала', 'только', 'уметь', 'тот', 'тою', 'хорошо', 'хотеть', 'хочешь', 'хоть', 'хотя', 'свое', 'свои', 'твой', 'своей', 'своего', 'своих', 'свою', 'твоя', 'твоё', 'раз', 'уже', 'сам', 'там', 'тем', 'чем', 'сама', 'сами', 'теми', 'само', 'рано', 'самом', 'самому', 'самой', 'самого', 'семнадцать', 'семнадцатый', 'самим', 'самими', 'самих', 'саму', 'семь', 'чему', 'раньше', 'сейчас', 'чего', 'сегодня', 'себе', 'тебе', 'сеаой', 'человек', 'разве', 'теперь', 'себя', 'тебя', 'седьмой', 'спасибо', 'слишком', 'так', 'такое', 'такой', 'такие', 'также', 'такая', 'сих', 'тех', 'чаще', 'четвертый', 'через', 'часто', 'шестой', 'шестнадцать', 'шестнадцатый', 'шесть', 'четыре', 'четырнадцать', 'четырнадцатый', 'сколько', 'сказал', 'сказала', 'сказать', 'ту', 'ты', 'три', 'эта', 'эти', 'что', 'это', 'чтоб', 'этом', 'этому', 'этой', 'этого', 'чтобы', 'этот', 'стал', 'туда', 'этим', 'этими', 'рядом', 'тринадцать', 'тринадцатый', 'этих', 'третий', 'тут', 'эту', 'суть', 'чуть', 'тысяч', 'кстати', 'когда-то', 'могу', 'свой', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '—', '»', '«', '.', '.', '.', '–', 'ю.', 'ш.', 'вакханки', 'прощайте', 'ольга', 'павла', 'ивановича', 'павел', 'иванович', 'павлу', 'ивановичу', 'оля', 'сережа', 'олечка', 'фогель', 'толбухиных', 'марья', 'евстафьевна', 'постой', 'тетушка', 'брюнетка', 'худенькая', 'павлом', 'ивановичем', 'нет', 'мария', 'фогель', 'павле', 'ивановиче', 'павля', 'иванович', 'ездил', 'ездивший', 'орел', 'толбухиной', 'ирины', 'матвеевны', 'ирина', 'матвеевна', 'фу', 'ольгу', 'скандалу-то', 'анну', 'анна', 'р**', 'оли', 'м.', 'е.', 'ф.', 'вася', 'васи', 'останься', 'оставшийся', 'усмешка', 'жюли', 'ксаверия', 'осиповича', 'ксаверий', 'осипович', 'штевичу', 'ивана', 'федоровича', 'иван', 'федорович', 'да-с', 'нет-с', 'яснев', 'добряк', 'юлия', 'николаевна', 'блудница', 'штевич', 'эх', 'поселимся', 'хромой', 'юше', 'послушай', 'поль', 'постоявший', 'помиритесь', 'юша', 'вишь', 'юшка', 'штевича', 'баба', 'куражился', 'полю', 'поле', 'жена-то', 'м-м', 'фогель', 'милая', 'ольга', 'федоровна', 'марья', 'евстафьевна', 'добрая', 'марья', 'евстафьевна', 'павел', 'иваныч', 'милая', 'марья', 'евстафьевна', 'павел', 'бодягин', 'бодягиным', 'бодягин', 'понятно-с', 'хорошенькую', 'маман', 'ольга', 'федоровна', 'темненько', 'мари', 'горько', 'напомните', 'напомнившие', 'бес', 'п**', 'бореля', 'борель', 'ольге', 'софья', 'антоновна', 'создателя', 'создатель', 'беременна', 'черезов', 'ольги', 'бабка', 'сергей', 'михайлович', 'черезов', 'поля', 'черезова', 'лжешь', 'мило', 'недоставало', 'намеков', 'садись', 'прибавь', 'эге', 'тьфу', 'сергей', 'михайлович', 'нанюхался', 'дон', 'жуан', 'пойдемте', 'пошедшие', 'дон', 'жуана', 'послушайте', 'угадайте', 'кончите', 'успокойтесь', 'успокоившиеся', 'а?..', 'отпираешься', 'темно', 'тсс', 'трус', 'маша', 'барин', 'якову', 'яков', 'голубчика', 'голубчик', 'нельзя-с', 'няня', 'пахомовна', 'бедняжка', 'анна', 'павловна', 'бог', 'ушиблась', 'д**', 'лекок', 'вон', 'стекольщиков', 'я-с', 'сударыня', 'эк', 'грешен', 'болен', 'черезову']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-46a72c37219d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mtopics_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtopic_extracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?<=\")\\w.*?(?=\")'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_extracted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics_book\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyldavis"
      ],
      "metadata": {
        "id": "rNU1VpoSE9EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis"
      ],
      "metadata": {
        "id": "d0gMBzTR9Gfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis = gensimvis.prepare(lda, corpus, gensim_dictionary_for_TM)"
      ],
      "metadata": {
        "id": "WWaYKCsi9MTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "R155fWRk9O6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis"
      ],
      "metadata": {
        "id": "gCbqnO0g9RVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwQUfu019TqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}