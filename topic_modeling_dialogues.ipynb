{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset with extracted dialogues"
      ],
      "metadata": {
        "id": "Q3S39LsIzaOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9f7qOHBWcfVf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/masters/try/last dataset/edited_dataset.csv')"
      ],
      "metadata": {
        "id": "mlhiE1S7dNPH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries "
      ],
      "metadata": {
        "id": "01hCeCzJzhDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install natasha"
      ],
      "metadata": {
        "id": "vi7gTrLdbsXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymorphy2"
      ],
      "metadata": {
        "id": "KgAVHSDFbxs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import download as nltk_download \n",
        "nltk_download ('punkt')"
      ],
      "metadata": {
        "id": "7awMQpLvzCxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, NewsNERTagger, Doc)\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)"
      ],
      "metadata": {
        "id": "mvaf2b-6zQhZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "parser = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "rgLGPLsVzRnR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "pGvmft9-ztPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "fTr1l2i6_wtG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial black list"
      ],
      "metadata": {
        "id": "0QUHoyLezzDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dhhse/dh2020/master/data/stop_ru.txt\n",
        "with open ('stop_ru.txt', 'r') as stop_file:\n",
        "    rus_stops = [word.strip() for word in stop_file.readlines()]"
      ],
      "metadata": {
        "id": "rSwdrXXXzIFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = '!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~—»«...–'\n"
      ],
      "metadata": {
        "id": "RYJeFPnTz1IX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling"
      ],
      "metadata": {
        "id": "6qZkP1cdz7tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "6bQPPNG-Rcho"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input_text):\n",
        "    tokenized_text = word_tokenize(input_text.lower())\n",
        "    output_text = [word for word in tokenized_text if word not in filters]\n",
        "    clean_text = [word for word in output_text if word.isalpha()]\n",
        "    lemmatized_text = [parser.parse(word)[0].normal_form for word in clean_text]\n",
        "    return lemmatized_text"
      ],
      "metadata": {
        "id": "46uC54Tr1u6H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = []\n",
        "titles = []\n",
        "topics = []"
      ],
      "metadata": {
        "id": "guOei5EnfXMj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(dataset['dialogues'].tolist())):\n",
        "  text = dataset['dialogues'].tolist()[index]\n",
        "  text_list = []\n",
        "  text_list.append(text)\n",
        "  doc_natasha = Doc(text)\n",
        "  doc_natasha.segment(segmenter)\n",
        "  doc_natasha.tag_morph(morph_tagger)\n",
        "  doc_natasha.parse_syntax(syntax_parser)\n",
        "  doc_natasha.tag_ner(ner_tagger)\n",
        "\n",
        "  names = []\n",
        "  for span in doc_natasha.spans:\n",
        "    if span.type == 'PER':\n",
        "      if span.text not in names:\n",
        "        names.append(span.text)\n",
        "      span.normalize(morph_vocab)\n",
        "      if span.normal not in names:\n",
        "        names.append(span.normal)\n",
        "  filters = rus_stops + list(punctuation)\n",
        "  for name in names:\n",
        "    word = name.lower()\n",
        "    filters = filters + word.split(' ')\n",
        "  preprocessed_texts = [preprocess(text_t) for text_t in text_list]\n",
        "  gensim_dictionary_for_TM = gensim.corpora.Dictionary(preprocessed_texts)\n",
        "  gensim_dictionary_for_TM.compactify()\n",
        "  corpus = [gensim_dictionary_for_TM.doc2bow(text_p) for text_p in preprocessed_texts]\n",
        "  lda = gensim.models.LdaMulticore(corpus,num_topics = 10, id2word=gensim_dictionary_for_TM, passes=10)\n",
        "  topics_book = []\n",
        "  for topic in lda.print_topics():\n",
        "    topic_extracted = re.findall(r'(?<=\")\\w.*?(?=\")', topic[1])\n",
        "    for i in topic_extracted:\n",
        "      if i not in topics_book:\n",
        "        topics_book.append(i)\n",
        "  \n",
        "  author = dataset['author'].tolist()[index]\n",
        "  authors.append(author)\n",
        "  # extract book title \n",
        "  title = dataset['book'].tolist()[index]\n",
        "  titles.append(title)\n",
        "  # topics \n",
        "  topics.append(topics_book)\n",
        "\n",
        "df_columns = ['author', 'book', 'topics']\n",
        "dataframe = pd.DataFrame(columns = df_columns)\n",
        "dataframe['author'] = authors\n",
        "dataframe['book'] = titles\n",
        "dataframe['topics'] = topics\n",
        "\n",
        "# creating a dataset \n",
        "dataframe.to_csv('topics_dialogues.csv')"
      ],
      "metadata": {
        "id": "uCSD-boAdjpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyldavis"
      ],
      "metadata": {
        "id": "rNU1VpoSE9EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis"
      ],
      "metadata": {
        "id": "d0gMBzTR9Gfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis = gensimvis.prepare(lda, corpus, gensim_dictionary_for_TM)"
      ],
      "metadata": {
        "id": "WWaYKCsi9MTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "R155fWRk9O6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis"
      ],
      "metadata": {
        "id": "gCbqnO0g9RVd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}